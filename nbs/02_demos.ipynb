{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2], edge_index=[2])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "node_features = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index, edge_attr=torch.randn(4, 10))\n",
    "\n",
    "Data(edge_index=[2, 4], x=[3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically the same as the baseline except we pass edge features\n",
    "from torch_geometric.nn import GATConv, GATv2Conv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "\n",
    "class GATModel(nn.Module):\n",
    "    def __init__(self, node_embed_size=16, hidden_size=32, num_edge_features=10, max_nodes=100):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.node_embedding = nn.Embedding(max_nodes, node_embed_size)\n",
    "        # Initialize the embeddings with small random values\n",
    "        nn.init.normal_(self.node_embedding.weight, std=0.1)\n",
    "        self.convs = [\n",
    "            GATv2Conv(node_embed_size, self.hidden_size, edge_dim=num_edge_features),\n",
    "            GATv2Conv(self.hidden_size, self.hidden_size, edge_dim=num_edge_features),\n",
    "        ]\n",
    "        self.linear = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
    "        # want to get the node embeddings for the nodes in the batch\n",
    "        # get the node numbers for each graph in the batch (i.e. the number of nodes in each graph)\n",
    "        # data.batch is a tensor of size [num_nodes] that maps each node to its graph\n",
    "        \n",
    "        x = self.node_embedding.weight[:data.num_nodes,:]\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index, edge_attr=edge_attr)  # adding edge features here!\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.convs[-1](\n",
    "            x, edge_index, edge_attr=edge_attr\n",
    "        )  # edge features here as well\n",
    "        x = global_mean_pool(x, data.batch)  # [batch_size, hidden_channels]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khannay/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 401 is out of bounds for dimension 0 with size 400",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader([data, data], batch_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(model(batch))\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_embedding\u001b[39m.\u001b[39mweight[:data\u001b[39m.\u001b[39mnum_nodes,:]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvs[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     x \u001b[39m=\u001b[39m conv(x, edge_index, edge_attr\u001b[39m=\u001b[39;49medge_attr)  \u001b[39m# adding edge features here!\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/khannay/work/school/nyu/project-gnn/mdetect-gnn/nbs/02_demos.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch_geometric/nn/conv/gatv2_conv.py:237\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    234\u001b[0m         num_nodes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(num_nodes, x_r\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m))\n\u001b[1;32m    235\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m remove_self_loops(\n\u001b[1;32m    236\u001b[0m         edge_index, edge_attr)\n\u001b[0;32m--> 237\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m add_self_loops(\n\u001b[1;32m    238\u001b[0m         edge_index, edge_attr, fill_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_value,\n\u001b[1;32m    239\u001b[0m         num_nodes\u001b[39m=\u001b[39;49mnum_nodes)\n\u001b[1;32m    240\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[1;32m    241\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch_geometric/utils/loop.py:263\u001b[0m, in \u001b[0;36madd_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(fill_value, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    262\u001b[0m     col \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m is_sparse \u001b[39melse\u001b[39;00m edge_index[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 263\u001b[0m     loop_attr \u001b[39m=\u001b[39m scatter(edge_attr, col, \u001b[39m0\u001b[39;49m, N, fill_value)\n\u001b[1;32m    264\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo valid \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfill_value\u001b[39m\u001b[39m'\u001b[39m\u001b[39m provided\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gnnflows/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:74\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     73\u001b[0m     count \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mnew_zeros(dim_size)\n\u001b[0;32m---> 74\u001b[0m     count\u001b[39m.\u001b[39;49mscatter_add_(\u001b[39m0\u001b[39;49m, index, src\u001b[39m.\u001b[39;49mnew_ones(src\u001b[39m.\u001b[39;49msize(dim)))\n\u001b[1;32m     75\u001b[0m     count \u001b[39m=\u001b[39m count\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m     index \u001b[39m=\u001b[39m broadcast(index, src, dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 401 is out of bounds for dimension 0 with size 400"
     ]
    }
   ],
   "source": [
    "model = GATModel(hidden_size=32, num_edge_features=10, max_nodes=400)\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader([data, data], batch_size=2)\n",
    "for batch in dataloader:\n",
    "    print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake test graph data\n",
    "from typing import Callable, Optional\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "\n",
    "class FakeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, size: int = 100, mean_sep: float = 3.0):\n",
    "        self.size = size\n",
    "        self.data_list = [\n",
    "            self.generate_random_graph(mean_edge=0.0) for _ in range(size)\n",
    "        ]\n",
    "        self.data_list += [\n",
    "            self.generate_random_graph(mean_edge=mean_sep) for _ in range(size)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size * 2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "    def generate_random_graph(self, mean_edge: float = 0.0):\n",
    "        edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "\n",
    "        y_label = (\n",
    "            torch.tensor([0], dtype=torch.long)\n",
    "            if mean_edge <= 0.50\n",
    "            else torch.tensor([1], dtype=torch.long)\n",
    "        )\n",
    "        edges_attributes = mean_edge + torch.randn(4, 10)\n",
    "        data_obj = Data(\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edges_attributes,\n",
    "            y=y_label,\n",
    "        )\n",
    "        data_obj.num_nodes = 3\n",
    "        return data_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = FakeDataset(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], edge_attr=[4, 10], y=[1], num_nodes=3)\n"
     ]
    }
   ],
   "source": [
    "print(datalist[98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.7044002413749695\n",
      "Epoch 20 loss: 0.6833053231239319\n",
      "Epoch 30 loss: 0.713189423084259\n",
      "Epoch 40 loss: 0.28837788105010986\n",
      "Epoch 50 loss: 0.025703471153974533\n",
      "Epoch 60 loss: 0.0084714749827981\n",
      "Epoch 70 loss: 0.0133052384480834\n",
      "Epoch 80 loss: 0.003203689819201827\n",
      "Epoch 90 loss: 0.0004551921156235039\n",
      "Epoch 100 loss: 0.0020007677376270294\n",
      "Epoch 110 loss: 0.0007524141692556441\n",
      "Epoch 120 loss: 0.002096351934596896\n",
      "Epoch 130 loss: 0.0013564835535362363\n",
      "Epoch 140 loss: 0.00028539408231154084\n",
      "Epoch 150 loss: 0.0010591543978080153\n",
      "Epoch 160 loss: 0.0009831078350543976\n",
      "Epoch 170 loss: 0.00022370784427039325\n",
      "Epoch 180 loss: 0.00019172992324456573\n",
      "Epoch 190 loss: 0.00025751636712811887\n"
     ]
    }
   ],
   "source": [
    "fdataloader = DataLoader(FakeDataset(size=256), batch_size=64, shuffle=True)\n",
    "model = GATModel(node_embed_size=16, hidden_size=64, num_edge_features=10, max_nodes=10000)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(1,200):\n",
    "    for batch in fdataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch) % 10 == 0:\n",
    "        print(f\"Epoch {epoch} loss: {loss.item()}\")\n",
    "# define a training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model of Molecule Graph Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Number of edge features: 4\n",
      "Number of node features: 7\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of edge features: {data.num_edge_features}')\n",
    "print(f'Number of node features: {data.num_node_features}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 150\n",
      "Number of test graphs: 38\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:150]\n",
    "test_dataset = dataset[150:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 2636], x=[1188, 7], edge_attr=[2636, 4], y=[64], batch=[1188], ptr=[65])\n",
      "\n",
      "Step 2:\n",
      "=======\n",
      "Number of graphs in the current batch: 64\n",
      "DataBatch(edge_index=[2, 2506], x=[1139, 7], edge_attr=[2506, 4], y=[64], batch=[1139], ptr=[65])\n",
      "\n",
      "Step 3:\n",
      "=======\n",
      "Number of graphs in the current batch: 22\n",
      "DataBatch(edge_index=[2, 852], x=[387, 7], edge_attr=[852, 4], y=[22], batch=[387], ptr=[23])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Acc: 0.6467, Test Acc: 0.7632\n",
      "Epoch: 020, Train Acc: 0.4800, Test Acc: 0.4474\n",
      "Epoch: 030, Train Acc: 0.5933, Test Acc: 0.7105\n",
      "Epoch: 040, Train Acc: 0.3800, Test Acc: 0.3947\n",
      "Epoch: 050, Train Acc: 0.6267, Test Acc: 0.7368\n",
      "Epoch: 060, Train Acc: 0.6000, Test Acc: 0.6842\n",
      "Epoch: 070, Train Acc: 0.6733, Test Acc: 0.7105\n",
      "Epoch: 080, Train Acc: 0.6400, Test Acc: 0.5789\n",
      "Epoch: 090, Train Acc: 0.6467, Test Acc: 0.6579\n",
      "Epoch: 100, Train Acc: 0.6600, Test Acc: 0.7632\n",
      "Epoch: 110, Train Acc: 0.6600, Test Acc: 0.7105\n",
      "Epoch: 120, Train Acc: 0.6333, Test Acc: 0.7368\n",
      "Epoch: 130, Train Acc: 0.4867, Test Acc: 0.6316\n",
      "Epoch: 140, Train Acc: 0.6067, Test Acc: 0.6053\n",
      "Epoch: 150, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 160, Train Acc: 0.6333, Test Acc: 0.7368\n",
      "Epoch: 170, Train Acc: 0.6467, Test Acc: 0.6842\n",
      "Epoch: 180, Train Acc: 0.6533, Test Acc: 0.7368\n",
      "Epoch: 190, Train Acc: 0.6067, Test Acc: 0.6579\n",
      "Epoch: 200, Train Acc: 0.6133, Test Acc: 0.7105\n",
      "Epoch: 210, Train Acc: 0.4733, Test Acc: 0.4737\n",
      "Epoch: 220, Train Acc: 0.4667, Test Acc: 0.6053\n",
      "Epoch: 230, Train Acc: 0.6667, Test Acc: 0.7105\n",
      "Epoch: 240, Train Acc: 0.6133, Test Acc: 0.7632\n",
      "Epoch: 250, Train Acc: 0.6400, Test Acc: 0.7632\n",
      "Epoch: 260, Train Acc: 0.6533, Test Acc: 0.7368\n",
      "Epoch: 270, Train Acc: 0.6533, Test Acc: 0.6316\n",
      "Epoch: 280, Train Acc: 0.4400, Test Acc: 0.3947\n",
      "Epoch: 290, Train Acc: 0.5800, Test Acc: 0.6842\n",
      "Epoch: 300, Train Acc: 0.5533, Test Acc: 0.6316\n",
      "Epoch: 310, Train Acc: 0.5800, Test Acc: 0.6316\n",
      "Epoch: 320, Train Acc: 0.5333, Test Acc: 0.5789\n",
      "Epoch: 330, Train Acc: 0.6400, Test Acc: 0.5526\n",
      "Epoch: 340, Train Acc: 0.4000, Test Acc: 0.4737\n",
      "Epoch: 350, Train Acc: 0.6533, Test Acc: 0.7368\n",
      "Epoch: 360, Train Acc: 0.6333, Test Acc: 0.7368\n",
      "Epoch: 370, Train Acc: 0.6533, Test Acc: 0.6579\n",
      "Epoch: 380, Train Acc: 0.5333, Test Acc: 0.5263\n",
      "Epoch: 390, Train Acc: 0.6133, Test Acc: 0.7105\n",
      "Epoch: 400, Train Acc: 0.5000, Test Acc: 0.4474\n",
      "Epoch: 410, Train Acc: 0.5533, Test Acc: 0.7105\n",
      "Epoch: 420, Train Acc: 0.5800, Test Acc: 0.7105\n",
      "Epoch: 430, Train Acc: 0.5867, Test Acc: 0.7368\n",
      "Epoch: 440, Train Acc: 0.4400, Test Acc: 0.4474\n",
      "Epoch: 450, Train Acc: 0.4867, Test Acc: 0.6842\n",
      "Epoch: 460, Train Acc: 0.6333, Test Acc: 0.6842\n",
      "Epoch: 470, Train Acc: 0.5400, Test Acc: 0.6579\n",
      "Epoch: 480, Train Acc: 0.5533, Test Acc: 0.6316\n",
      "Epoch: 490, Train Acc: 0.5600, Test Acc: 0.6842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = GATModel(hidden_size=128, num_edge_features=4, max_nodes=10000)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "         out = model(data)  # Perform a single forward pass.\n",
    "         loss = criterion(out, data.y)  # Compute the loss.\n",
    "         loss.backward()  # Derive gradients.\n",
    "         optimizer.step()  # Update parameters based on gradients.\n",
    "         optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 500):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv \n",
    "\n",
    "class NNConvModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_edge_features: int = 10, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv1 = NNConv(in_channels=dataset.num_node_features, out_channels=32, nn=Linear(num_edge_features, 32))\n",
    "        self.conv2 = NNConv(32, 64, nn=Linear(10, 32))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
